{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division # ensure that all division is float division\n",
    "#from __future__ import print_function # print function works properly when used with paranthesis\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import all the necessary modules\n",
    "import os, sys, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neutral     1644\n",
       "Panthers     827\n",
       "Broncos      529\n",
       "Name: Support, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"tweets_sample.csv\")\n",
    "df.Support.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 9)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#veriify the size of our sample\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# map the label values for scikit-learn\n",
    "df[\"Label\"]=df.Support.map({\"Neutral\":0,\"Panthers\":1,\"Broncos\":2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rndm</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>favorited</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp_ms</th>\n",
       "      <th>Support</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "      <td>6.960000e+17</td>\n",
       "      <td>Sun Feb 07 19:14:38 +0000 2016</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>RT @WorldStarFunny: Panthers hitting the dab for Super Bowl 50 team photo ðŸ˜‚ https://t.co/ojAlhk73fV</td>\n",
       "      <td>1.450000e+12</td>\n",
       "      <td>Panthers</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>923</td>\n",
       "      <td>6.960000e+17</td>\n",
       "      <td>Sun Feb 07 19:14:58 +0000 2016</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>RT @Pokemon: It's Game Day, Trainers! Who's ready for #SB50? #Pokemon20 https://t.co/qoeQKaXP7i</td>\n",
       "      <td>1.450000e+12</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1039</td>\n",
       "      <td>6.960000e+17</td>\n",
       "      <td>Sun Feb 07 19:15:00 +0000 2016</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Except Star he a trill nigga!  https://t.co/IeTbb5AMUq</td>\n",
       "      <td>1.450000e+12</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1617</td>\n",
       "      <td>6.960000e+17</td>\n",
       "      <td>Sun Feb 07 19:15:13 +0000 2016</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>#SuperBowl night lets get it on. If Broncos defence shuts down cam it's Broncos ftw</td>\n",
       "      <td>1.450000e+12</td>\n",
       "      <td>Broncos</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1784</td>\n",
       "      <td>6.960000e+17</td>\n",
       "      <td>Sun Feb 07 19:15:17 +0000 2016</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>RT @esurance: RT during the big game for your shot at a big gain. #EsuranceSweepstakes #SB50 https://t.co/Nm8UJicH6b</td>\n",
       "      <td>1.450000e+12</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rndm            id                      created_at  favorite_count  \\\n",
       "0    67  6.960000e+17  Sun Feb 07 19:14:38 +0000 2016               0   \n",
       "1   923  6.960000e+17  Sun Feb 07 19:14:58 +0000 2016               0   \n",
       "2  1039  6.960000e+17  Sun Feb 07 19:15:00 +0000 2016               0   \n",
       "3  1617  6.960000e+17  Sun Feb 07 19:15:13 +0000 2016               0   \n",
       "4  1784  6.960000e+17  Sun Feb 07 19:15:17 +0000 2016               0   \n",
       "\n",
       "  favorited retweeted  \\\n",
       "0     False     False   \n",
       "1     False     False   \n",
       "2     False     False   \n",
       "3     False     False   \n",
       "4     False     False   \n",
       "\n",
       "                                                                                                                   text  \\\n",
       "0                  RT @WorldStarFunny: Panthers hitting the dab for Super Bowl 50 team photo ðŸ˜‚ https://t.co/ojAlhk73fV   \n",
       "1                       RT @Pokemon: It's Game Day, Trainers! Who's ready for #SB50? #Pokemon20 https://t.co/qoeQKaXP7i   \n",
       "2                                                                Except Star he a trill nigga!  https://t.co/IeTbb5AMUq   \n",
       "3                                   #SuperBowl night lets get it on. If Broncos defence shuts down cam it's Broncos ftw   \n",
       "4  RT @esurance: RT during the big game for your shot at a big gain. #EsuranceSweepstakes #SB50 https://t.co/Nm8UJicH6b   \n",
       "\n",
       "   timestamp_ms   Support  Label  \n",
       "0  1.450000e+12  Panthers      1  \n",
       "1  1.450000e+12   Neutral      0  \n",
       "2  1.450000e+12   Neutral      0  \n",
       "3  1.450000e+12   Broncos      2  \n",
       "4  1.450000e+12   Neutral      0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#determine feature and label variables\n",
    "X=df.text\n",
    "y=df.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#perform train/test split with startify option to keep the proportion of teams the same for test and train variable\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2250L,)\n",
      "(2250L,)\n"
     ]
    }
   ],
   "source": [
    "#we can see 75% of data will be trained\n",
    "print (X_train.shape)\n",
    "print (y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2250x5827 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 29662 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instantiate/fit train data /transform to learn vocab of data\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect=CountVectorizer()\n",
    "X_train_dtm=vect.fit_transform(X_train)\n",
    "X_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<750x5827 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 8576 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transform to learn vocab of test data WARNING DO NOT FIT!\n",
    "X_test_dtm=vect.transform(X_test)\n",
    "X_test_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2412</th>\n",
       "      <td>1477</td>\n",
       "      <td>https</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4294</th>\n",
       "      <td>1412</td>\n",
       "      <td>rt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>1394</td>\n",
       "      <td>co</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4988</th>\n",
       "      <td>1179</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4376</th>\n",
       "      <td>943</td>\n",
       "      <td>sb50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3724</th>\n",
       "      <td>596</td>\n",
       "      <td>panthers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5087</th>\n",
       "      <td>540</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>517</td>\n",
       "      <td>broncos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961</th>\n",
       "      <td>429</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4836</th>\n",
       "      <td>334</td>\n",
       "      <td>superbowl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4832</th>\n",
       "      <td>300</td>\n",
       "      <td>super</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>288</td>\n",
       "      <td>bowl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5553</th>\n",
       "      <td>264</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>255</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2504</th>\n",
       "      <td>251</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>225</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5746</th>\n",
       "      <td>209</td>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2766</th>\n",
       "      <td>207</td>\n",
       "      <td>keeppounding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3568</th>\n",
       "      <td>205</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3619</th>\n",
       "      <td>192</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2566</th>\n",
       "      <td>176</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>174</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4846</th>\n",
       "      <td>168</td>\n",
       "      <td>superbowlsunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>168</td>\n",
       "      <td>cam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5033</th>\n",
       "      <td>167</td>\n",
       "      <td>this</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count           tokens\n",
       "2412   1477            https\n",
       "4294   1412               rt\n",
       "1210   1394               co\n",
       "4988   1179              the\n",
       "4376    943             sb50\n",
       "3724    596         panthers\n",
       "5087    540               to\n",
       "912     517          broncos\n",
       "1961    429              for\n",
       "4836    334        superbowl\n",
       "4832    300            super\n",
       "863     288             bowl\n",
       "5553    264              win\n",
       "2558    255               is\n",
       "2504    251               in\n",
       "473     225              and\n",
       "5746    209              you\n",
       "2766    207     keeppounding\n",
       "3568    205               of\n",
       "3619    192               on\n",
       "2566    176               it\n",
       "194     174               50\n",
       "4846    168  superbowlsunday\n",
       "999     168              cam\n",
       "5033    167             this"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store token names\n",
    "X_train_tokens = vect.get_feature_names()\n",
    "import numpy as np\n",
    "X_train_counts=np.sum(X_train_dtm.toarray(),axis=0)\n",
    "pd.DataFrame({\"tokens\":X_train_tokens,\"count\":X_train_counts}).sort_values(by=\"count\",ascending=False).head(25)\n",
    "#need to remove rts\n",
    "#need to remove non-text characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "def tokenize_test(vect):\n",
    "    X_train_dtm=vect.fit_transform(X_train)\n",
    "    print \"Features: \",X_train_dtm.shape[1]\n",
    "    X_test_dtm=vect.transform(X_test)\n",
    "    nb=MultinomialNB()\n",
    "    nb.fit(X_train_dtm,y_train)\n",
    "    y_pred_class=nb.predict(X_test_dtm)\n",
    "    print \"Accuracy: \",metrics.accuracy_score(y_test,y_pred_class)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  5827\n",
      "Accuracy:  0.801333333333\n"
     ]
    }
   ],
   "source": [
    "#with feature modification\n",
    "vect=CountVectorizer()\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  40536\n",
      "Accuracy:  0.828\n"
     ]
    }
   ],
   "source": [
    "# include n-grams\n",
    "vect=CountVectorizer(ngram_range=(1,3))\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  5618\n",
      "Accuracy:  0.809333333333\n"
     ]
    }
   ],
   "source": [
    "#remove stop words\n",
    "vect=CountVectorizer(stop_words=\"english\")\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  10000\n",
      "Accuracy:  0.844\n"
     ]
    }
   ],
   "source": [
    "#max features\n",
    "vect=CountVectorizer(max_features=10000,ngram_range=(1,3))\n",
    "tokenize_test(vect)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  40532\n",
      "Accuracy:  0.838666666667\n"
     ]
    }
   ],
   "source": [
    "#only include terms that appear at least twice\n",
    "vect=CountVectorizer(ngram_range=(1,3),max_df=100*12)\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob, Word\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "%matplotlib inline\n",
    "#initialize stemmer\n",
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#use svm \n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_svc=svm.SVC(kernel='linear')\n",
    "linear_svc.fit(X_train_dtm,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_linear_svm_test(vect):\n",
    "    X_train_dtm=vect.fit_transform(X_train)\n",
    "    print \"Features: \",X_train_dtm.shape[1]\n",
    "    X_test_dtm=vect.transform(X_test)\n",
    "    linear_svc=svm.SVC(kernel='linear')\n",
    "    linear_svc.fit(X_train_dtm,y_train)\n",
    "    y_pred_class=linear_svc.predict(X_test_dtm)\n",
    "    print \"Accuracy: \",metrics.accuracy_score(y_test,y_pred_class)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  10000\n",
      "Accuracy:  0.88\n"
     ]
    }
   ],
   "source": [
    "#max features | SVM with linear kernel\n",
    "vect=CountVectorizer(max_features=10000,ngram_range=(1,3))\n",
    "\n",
    "tokenize_linear_svm_test(vect)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rbf_svm(vect,c):\n",
    "    X_train_dtm=vect.fit_transform(X_train)\n",
    "    print \"Features: \",X_train_dtm.shape[1]\n",
    "    X_test_dtm=vect.transform(X_test)\n",
    "    linear_svm=svm.SVC(kernel='rbf',C=c)\n",
    "    t0 = time()\n",
    "    linear_svm.fit(X_train_dtm,y_train)\n",
    "    print \"training time:\", round(time()-t0, 3), \"s\"\n",
    "\n",
    "    t0 = time()\n",
    "    y_pred_class=linear_svm.predict(X_test_dtm)\n",
    "    print \"predicting time:\", round(time()-t0, 3), \"s\"\n",
    "\n",
    "    #########################################################\n",
    "    from sklearn import metrics\n",
    "    print \"Accuracy: \",metrics.accuracy_score(y_test,y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  10000\n",
      "training time: 0.462 s\n",
      "predicting time: 0.132 s\n",
      "Accuracy:  0.878666666667\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "rbf_svm(vect,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  10000\n",
      "training time: 0.429 s\n",
      "predicting time: 0.12 s\n",
      "Accuracy:  0.893333333333\n"
     ]
    }
   ],
   "source": [
    "rbf_svm(vect,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  10000\n",
      "training time: 0.446 s\n",
      "predicting time: 0.135 s\n",
      "Accuracy:  0.893333333333\n"
     ]
    }
   ],
   "source": [
    "rbf_svm(vect,470)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation before PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  10000\n",
      "Accuracy:  0.844\n",
      "Features:  10000\n",
      "confusion matrix for Multinomial Naive Bayes [[388  15   8]\n",
      " [ 33 159  15]\n",
      " [ 33  13  86]]\n",
      "Features:  10000\n",
      "confusion matrix for Linear SVM [[379  20  12]\n",
      " [ 18 177  12]\n",
      " [ 16  12 104]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "nb = MultinomialNB()\n",
    "vect=CountVectorizer(max_features=10000,ngram_range=(1,3))\n",
    "tokenize_test(vect) \n",
    "def confusion_nb_ROC(vect):\n",
    "    X_train_dtm=vect.fit_transform(X_train)\n",
    "    print \"Features: \",X_train_dtm.shape[1]\n",
    "    X_test_dtm=vect.transform(X_test)\n",
    "    nb=MultinomialNB()\n",
    "    nb.fit(X_train_dtm,y_train)\n",
    "    y_pred_class=nb.predict(X_test_dtm)\n",
    "    y_pred_prob=nb.predict_proba(X_test_dtm)[:,2]\n",
    "    #fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_prob)\n",
    "    \n",
    "    print \"confusion matrix for Multinomial Naive Bayes\",metrics.confusion_matrix(y_test, y_pred_class)\n",
    "\n",
    "def confusion_linear_svm_test(vect):\n",
    "    X_train_dtm=vect.fit_transform(X_train)\n",
    "    print \"Features: \",X_train_dtm.shape[1]\n",
    "    X_test_dtm=vect.transform(X_test)\n",
    "    linear_svc=svm.SVC(kernel='linear')\n",
    "    linear_svc.fit(X_train_dtm,y_train)\n",
    "    y_pred_class=linear_svc.predict(X_test_dtm)\n",
    "   \n",
    "    print \"confusion matrix for Linear SVM\", metrics.confusion_matrix(y_test,y_pred_class)\n",
    "     \n",
    "\n",
    "confusion_nb_ROC(vect)  \n",
    "confusion_linear_svm_test(vect)\n",
    "\n",
    "\n",
    "#the linear svm is better at predicting team classes than naive bayes, naive bayes excells at "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sw=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'ascii' codec can't encode character u'\\u2026' in position 139: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-7a40bf205dd4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mParseOutText\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstemmed_word\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msplit_into_lemmas\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mvect\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manalyzer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstemmed_word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mrbf_svm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvect\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m470\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-85-55b689a92327>\u001b[0m in \u001b[0;36mrbf_svm\u001b[1;34m(vect, c)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrbf_svm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvect\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mX_train_dtm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Features: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train_dtm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mX_test_dtm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mlinear_svm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rbf'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dominique Njinkeu\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\sklearn\\feature_extraction\\text.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m    815\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[1;32m--> 817\u001b[1;33m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    819\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dominique Njinkeu\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\sklearn\\feature_extraction\\text.pyc\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m    750\u001b[0m         \u001b[0mindptr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    751\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 752\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    753\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    754\u001b[0m                     \u001b[0mj_indices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dominique Njinkeu\\Documents\\GitHub\\Projects\\notebook\\ParseOutText.py\u001b[0m in \u001b[0;36mstemmed_word\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mstemmed_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;31m#text = unicode(text, 'utf-8').lower()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ascii'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ascii\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[0mw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTextBlob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'ascii' codec can't encode character u'\\u2026' in position 139: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "#stemming\n",
    "from ParseOutText import stemmed_word,split_into_lemmas\n",
    "vect=CountVectorizer(analyzer=stemmed_word)\n",
    "rbf_svm(vect,470)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w=TextBlob(str(df.text.sample(1)))\n",
    "words=[stemmer.stem(word) for word in w.words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#do stemming before bag of words--trick 1\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TfIdf Representation\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
